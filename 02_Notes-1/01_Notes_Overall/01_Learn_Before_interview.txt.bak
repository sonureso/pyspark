Q1. Create a dataframe in spark.
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DoubleType
spark = SparkSession.builder.master("local[*]").getOrCreate()
new_schema = StructType([
			StructField("col1", IntegerType(), True),
			StructField("col2", StringType(), False),
			StructField("col3", StringType(), False)
			])
data = [("James","","Smith","36636","M",3000),
    ("Michael","Rose","","40288","M",4000),
    ("Robert","","Williams","42114","M",4000),
    ("Maria","Anne","Jones","39192","F",4000),
    ("Jen","Mary","Brown","","F",-1)
  ]

df = spark.createDataFrame(data=data,schema=schema)
=============================================================
Q2. Syntax for window functions. Find rank of intgross year wise.
from pyspark.sql.window import Window
from pyspark.sql import functions as F
windowSpec = Window().partitionBy(['year']).orderBy(df1['intgross'].desc())
df1.withColumn("rank",F.rank().over(windowSpec)).select('year','intgross','rank').show(7)
=============================================================
Q3. Read CSV or json files:
df = spark.read.json("filepath.json")
df = spark.read.csv("movies.csv",header=True,sep=",",inferSchema=True)
df = spark.read.option("header",True).option("delimiter",",").option("inferSchema",True).csv("movies.csv")
=============================================================
Q4. Broadcast join in Pyspark:
from pyspark.sql.functions import broadcast
result = big_df.join(broadcast(small_df), big_df["product_id"] == small_df["product_id"])
=============================================================
Q5. What is stage and tasks:
Spark Application -> many jobs -> many stages -> many tasks.
JOBS: A job is defined as a series of stages combined.
STAGES: A stage is a group of tasks executed together. 
=============================================================
Q6. Narrow and Wide transformation:
• NARROW: These types of transformations convert each input partition to only one output partition.
When each partition at the parent RDD is used by at most one partition of the child RDD or 
when each partition from child produced or dependent on single parent RDD.
Operation of map()and filter() belongs to this narrow transformations.
• WIDE: This type of transformation will have input partitions contributing to many output partitions.
Might Require data shuffling over the cluster network or no data movement.
Functions such as groupByKey(), aggregateByKey(), aggregate(), join(), repartition() are some examples of wider transformations.
=============================================================


















