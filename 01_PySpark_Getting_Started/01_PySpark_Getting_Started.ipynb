{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics Covered:\n",
    "    1. Creating Spark SQL Session\n",
    "    2. Creating Spark Context\n",
    "    3. Using RDD, map and take\n",
    "    4. Reading text file and applying actions\n",
    "    5. Examples: Transformations\n",
    "    6. Connecting to MySQL\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Creating a Spark SQL Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "#spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Creating a Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x219950780c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "conf = SparkConf()\n",
    "conf.setMaster('local')\n",
    "conf.setAppName('spark-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"spark-basic\")\n",
    "#sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Using RDD, map and take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (2, 0), (3, 1), (4, 0), (5, 1), (6, 0), (7, 1), (8, 0), (9, 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1000)).map(lambda x:(x,x%2)).take(10)\n",
    "print(rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Reading text file and applying actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading TXT File and use pre-defined functions:\n",
    "count, collect,first,take,takeSample,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a text file:\n",
    "txt = sc.textFile('hello.txt')\n",
    "type(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first():  Line 1\n",
      "count():  1244\n",
      "take():  ['Line 1', 'Line 2', 'Line 3', 'Line 4', 'Line 5']\n",
      "takeSample():  ['Last Line it is.', 'This is line number two', 'Welcome to PySpark!!', 'Last Line it is.', 'Line 3']\n"
     ]
    }
   ],
   "source": [
    "txt.collect() # rdd got converted to list format.\n",
    "print(\"first(): \",txt.first())\n",
    "print(\"count(): \",txt.count())\n",
    "print(\"take(): \",txt.take(5))\n",
    "print(\"takeSample(): \",txt.takeSample(False,5,1)) # takes 5 samples with or without(True or False) replacement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Examples: Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformations: map,flastmap,filter,mapPartitions,mapPartitionsWithIndex,sample,union,intersection,distinct groupBy,keyBy,Zip,zipwithIndex,Coalesce,Repartition,sortBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red2', 'Green2', 'Blue2', 'Yellow2']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using map:\n",
    "x = sc.parallelize([\"Red\",\"Green\",\"Blue\",\"Yellow\"])\n",
    "y = x.map(lambda x:(x+str(2)))\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "#Using flatMap:\n",
    "x = sc.parallelize([2,3,4])\n",
    "y = x.flatMap(lambda x:range(1,x)).collect()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 8, 8, 6]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Filter:\n",
    "x = sc.parallelize([2,5,6,8,1,5,8,9,6,3])\n",
    "y = x.filter(lambda x : x%2==0).collect()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 6, 8]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "#Take one sample without replacement from each cluster:\n",
    "x = sc.parallelize(range(1,10))\n",
    "print(x.sample(False,0.8,2).collect()) # (with or without replacement,fraction,seed)\n",
    "print(x.sample(False,1,2).collect()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union:  [1, 2, 3, 4, 5, 6, 7, 8, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  Intersection:  [6, 8, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "#Union&intersection:\n",
    "x = sc.parallelize(range(1,9))\n",
    "y = sc.parallelize(range(5,15))\n",
    "z = x.union(y).collect()\n",
    "z2 = x.intersection(y).collect()\n",
    "print(\"Union: \",z,\" Intersection: \",z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 10), ('F', 222), ('I', 15), ('Z', 28)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sortBy:\n",
    "#x = sc.parallelize([2,8,9,5,4,7,1,1,2,3])\n",
    "#x.sortBy(lambda x:x,True).collect()\n",
    "y = sc.parallelize([(\"F\",222),(\"Z\",28),(\"I\",15),(\"D\",10)])\n",
    "y.sortBy(lambda x:x,True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 15]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapPartitios:\n",
    "x = sc.parallelize([1,2,3,4,5,6],2)\n",
    "def f(cluster): yield sum(cluster)\n",
    "x.mapPartitions(f).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapPartitios with index:\n",
    "x = sc.parallelize([1,2,3,4,5,6],5)\n",
    "def f(index,cluster): yield index\n",
    "x.mapPartitionsWithIndex(f).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [2, 8]), (1, [1, 1, 3, 5])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupBy:\n",
    "rdd = sc.parallelize([1,1,2,3,5,8])\n",
    "result = rdd.groupBy(lambda x: x%2).collect()\n",
    "sorted([(x,sorted(y)) for (x,y) in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [[0], [0]]),\n",
       " (1, [[1], [1]]),\n",
       " (2, [[], [2]]),\n",
       " (3, [[], [3]]),\n",
       " (4, [[2], [4]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keyBy:\n",
    "x = sc.parallelize(range(0,3)).keyBy(lambda x:x*x)\n",
    "y = sc.parallelize(zip(range(0,5), range(0,5)))\n",
    "[(x, list(map(list,y))) for x,y in sorted(x.cogroup(y).collect())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zip:\n",
    "x = sc.parallelize(range(0,5))\n",
    "y = sc.parallelize(range(1000,1005))\n",
    "x.zip(y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0), ('b', 1), ('c', 2), ('d', 3)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zip:\n",
    "sc.parallelize([\"a\",\"b\",\"c\",\"d\"]).zipWithIndex().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2, 3], [4, 5], [6, 7]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#partitioning:\n",
    "rdd = sc.parallelize([1,2,3,4,5,6,7],4)\n",
    "rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 5, 6, 7], [2, 3]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.repartition(2).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2, 3], [4, 5]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Coalesce:\n",
    "sc.parallelize([1,2,3,4,5],3).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2, 3, 4, 5]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([1,2,3,4,5],3).coalesce(2).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Connecting to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"sonuresodb\"\n",
    "table = \"lyrics\"\n",
    "user = \"root\"\n",
    "password  = \"\"\n",
    "\n",
    "jdbcDF = spark.read.format(\"jdbc\").option(\"url\", f\"jdbc:sqlserver://localhost:3306;databaseName={database};\") \\\n",
    "    .option(\"dbtable\", table) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password).option(\"driver\", \"com.mysql.jdbc.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====END============"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
